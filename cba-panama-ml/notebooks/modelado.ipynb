{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9e661570",
   "metadata": {},
   "source": [
    "### Modelado de Regresión y Clasificación"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "883d63bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "from sklearn.metrics import (\n",
    "    f1_score,\n",
    "    roc_auc_score,\n",
    "    average_precision_score\n",
    ")\n",
    "\n",
    "import sys\n",
    "\n",
    "# Carga del script que contiene las rutinas comúnes para el modelado.\n",
    "sys.path.append('../scripts')\n",
    "import modelos_common as mcom"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d140ffb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Se carga el dataset ya procesado y filtrado.\n",
    "main_df = mcom.get_dataframe()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "259c73da",
   "metadata": {},
   "source": [
    "### Regresión\n",
    "\n",
    "Para el análisis de regresión, se utilizan los modelos Ridge, RandomForestRegressor y HistGradientBoostingRegressor. Como baseline, se utiliza un DummyRegressor con strategy='mean'.\n",
    "\n",
    "La estrategia es generar regresiones por cada cadena de supermercados. Es posible efectuar una única regresión para todo el dataset completo, pero para evitar que la influencia de variación de costos de una cadena de supermercados afecte la regresión de otro, se opta por hacer regreseiones separadas. Hay que tener presente que no todas las cadenas presentan la misma variabilidad en sus costos de productos.\n",
    "\n",
    "Las variables a utilizar en la regresión son el producto_id, cadena_id y supermercado_id. Como ya las variables categóricas fueron codificadas con ids, no es necesario utilizar One-Hot Encoder. La variable objetivo es el costo. Esto lo podemos encontrar en la librería de rutinas comúnes (iter_regresion_Xy)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "851eae1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "metricas = []\n",
    "\n",
    "# Se recorre cada cadena, junto con sus variables X, y objetivo y.\n",
    "for cadena_name, X, y, _ in mcom.iter_regresion_Xy(main_df):\n",
    "    # separación de datos de prueba y entrenamiento.\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "    # Se recorre todos los modelos de regresión contemplados para el análisis. Los modelos están definidos en la librería de rutinas comúnes.\n",
    "    for reg_nombre, reg in mcom.ALL_REGRESION.items():\n",
    "        modelo = Pipeline([\n",
    "            ('scaler', StandardScaler()),\n",
    "            ('regresion', reg),\n",
    "        ])\n",
    "        \n",
    "        modelo.fit(X_train, y_train)\n",
    "        y_pred = modelo.predict(X_test)\n",
    "        \n",
    "        # el modelo ajustado se guarda en disco para su posterior uso.\n",
    "        mcom.guardar_modelo(modelo, 'regresion/{} - {}.joblib'.format(cadena_name, reg_nombre))\n",
    "        \n",
    "\t\t# Cálculo de las métricas MAE, RMSE y WMAPE\n",
    "        mae = mcom.calcular_mae(y_test, y_pred)\n",
    "        rmse = mcom.calcular_rmse(y_test, y_pred)\n",
    "        wmape = mcom.calcular_wmape(y_test, y_pred)\n",
    "        \n",
    "        metricas.append({\n",
    "            'cadena': cadena_name,\n",
    "            'regresion': reg_nombre,\n",
    "            'MAE': mae,\n",
    "            'RMSE': rmse,\n",
    "            'WMAPE': wmape,\n",
    "        })\n",
    "    \n",
    "metricas = pd.DataFrame(metricas)\n",
    "display(metricas)    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b634bdc1",
   "metadata": {},
   "source": [
    "### Clasificación\n",
    "\n",
    "Para la clasificación se efectúa algo similar a la regresión. Se analizará en base a las cadenas de supermercados por separado. Se utilizarán los modelos LogisticRegression, RandomForestClassifier, HistGradientBoostingClassifier y DummyClassifier estratificado como baseline para mantener la misma distribución de clases como en la data de entrenamiento."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a38e95aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "metricas = []\n",
    "\n",
    "for cadena_name, X, y, _ in mcom.iter_clasificacion_Xy(main_df):\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, stratify=y, test_size=0.2, random_state=42)\n",
    "    \n",
    "    for cls_nombre, cls in mcom.ALL_CLASIFICACION.items():\n",
    "        modelo = Pipeline([\n",
    "            ('scaler', StandardScaler()),\n",
    "            ('clasificador', cls),\n",
    "        ])\n",
    "        \n",
    "        modelo.fit(X_train, y_train)\n",
    "        y_pred = modelo.predict(X_test)\n",
    "        \n",
    "        # Se guarda el modelo en disco.\n",
    "        mcom.guardar_modelo(modelo, 'clasificacion/{} - {}.joblib'.format(cadena_name, cls_nombre))\n",
    "        \n",
    "        # Algunos modelos generan probabilidades, por lo que hay que verificar cuáles lo hacen. En estos casos, se utiliza su salida de probabilidad.\n",
    "        if hasattr(modelo.named_steps[\"clasificador\"], \"predict_proba\"):\n",
    "            y_proba = modelo.predict_proba(X_test)[:, 1]\n",
    "        elif hasattr(modelo.named_steps[\"clasificador\"], \"decision_function\"):\n",
    "            y_proba = modelo.decision_function(X_test)\n",
    "        else:\n",
    "            y_proba = None\n",
    "        \n",
    "        # Cálculo de las métricas de evaluación.\n",
    "        f1 = f1_score(y_test, y_pred, average='macro')\n",
    "        roc_auc = None if y_proba is None else roc_auc_score(y_test, y_proba)\n",
    "        pr_auc = None if y_proba is None else average_precision_score(y_test, y_proba)\n",
    "        \n",
    "        metricas.append({\n",
    "            'cadena': cadena_name,\n",
    "            'clasificador': cls_nombre,\n",
    "            'F1': f1,\n",
    "            'ROC-AUC': roc_auc,\n",
    "            'PR-AUC': pr_auc,\n",
    "        })\n",
    "\n",
    "metricas = pd.DataFrame(metricas)\n",
    "display(metricas)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "modelos_predictivos (3.11.9)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
