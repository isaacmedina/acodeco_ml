{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "883d63bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.dummy import DummyRegressor, DummyClassifier\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "from sklearn.ensemble import (\n",
    "    RandomForestRegressor,\n",
    "    HistGradientBoostingRegressor,\n",
    "    RandomForestClassifier,\n",
    "    HistGradientBoostingClassifier\n",
    ")\n",
    "\n",
    "from sklearn.model_selection import (\n",
    "    KFold,\n",
    "    StratifiedKFold,\n",
    "    train_test_split,\n",
    "    cross_validate,\n",
    "    cross_val_score\n",
    ")\n",
    "\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.linear_model import Ridge, LogisticRegression\n",
    "\n",
    "from sklearn.metrics import (\n",
    "    mean_absolute_error,\n",
    "    mean_squared_error,\n",
    "    f1_score,\n",
    "    roc_auc_score,\n",
    "    average_precision_score\n",
    ")\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import joblib\n",
    "import os\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d140ffb",
   "metadata": {},
   "outputs": [],
   "source": [
    "main_df = pd.read_csv('../data/processed/datasets_merged_cleaned.csv')\n",
    "\n",
    "main_df['fecha'] = pd.to_datetime(main_df['anio'].astype(str) + '-' + main_df['mes'].astype(str), format='%Y-%m')\n",
    "unique_cadenas = set([(a,b) for a,b in main_df[['cadena_id', 'cadena']].values])\n",
    "\n",
    "# Guarda en disco el modelo en formato joblib para su posterior uso.\n",
    "def guardar_modelo(modelo, filename):\n",
    "    path = os.path.join('../models', filename)\n",
    "    \n",
    "    try: os.makedirs(os.path.dirname(path))\n",
    "    except: pass\n",
    "\n",
    "    joblib.dump(modelo, path)\n",
    "\n",
    "# carga un modelo desde disco\n",
    "def cargar_modelo(filename):\n",
    "    path = os.path.join('../models', filename)\n",
    "    \n",
    "    if os.path.exists(path): return joblib.load(path)\n",
    "    return None"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "259c73da",
   "metadata": {},
   "source": [
    "REGRESION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "851eae1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "calcular_rmse = lambda y_test, y_pred: np.sqrt(mean_squared_error(y_test, y_pred))\n",
    "calcular_mae = lambda y_test, y_pred: mean_absolute_error(y_test, y_pred)\n",
    "calcular_wmape = lambda y_test, y_pred: np.sum(np.abs(y_test - y_pred)) / np.sum(np.abs(y_test))\n",
    "\n",
    "# Iterador, genera una tupla (cadena, X, y).\n",
    "def iter_regresion_Xy():\n",
    "\t# Las regresiones se harán en grupos separados por cadena de supermercados, ya que se quiere evitar\n",
    "\t# la influencia de los precios de una cadena sobre los de otra. Usualmente una misma cadena oscila sus\n",
    "\t# precios de forma regular.\n",
    "\tfor cadena_id,cadena_name in unique_cadenas:\n",
    "\t\tdf = main_df[main_df.cadena_id == cadena_id]\n",
    "\t\t\n",
    "\t\t# Ya fueron codificadas previamente las variables categóricas, por lo que se utilizan sus ids directamente.\n",
    "\t\tX = df[['supermercado_id', 'cadena_id', 'producto_id']]\n",
    "\t\ty = df['costo']\n",
    "\t\t\n",
    "\t\tyield cadena_name, X, y\n",
    "\n",
    "# Listado de todos los modelos de regresión que se utilizarán para el análisis.\n",
    "all_regresion = {\n",
    "    'Baseline': DummyRegressor(strategy='mean'),\n",
    "    'Ridge': Ridge(alpha=1.0, max_iter=10000),\n",
    "    'RandomForest': RandomForestRegressor(random_state=42),\n",
    "    'HistGradientBoosting': HistGradientBoostingRegressor(random_state=42),\n",
    "}\n",
    "\n",
    "metricas = []\n",
    "\n",
    "for cadena_name, X, y in iter_regresion_Xy():\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "    for reg_nombre, reg in all_regresion.items():\n",
    "        modelo = Pipeline([\n",
    "            ('scaler', StandardScaler()),\n",
    "            ('regresion', reg),\n",
    "        ])\n",
    "        \n",
    "        modelo.fit(X_train, y_train)\n",
    "        y_pred = modelo.predict(X_test)\n",
    "                \n",
    "        guardar_modelo(modelo, 'regresion/{} - {}.joblib'.format(cadena_name, reg_nombre))\n",
    "        \n",
    "\t\t# Cálculo de las métricas MAE, RMSE y WMAPE\n",
    "        mae = calcular_mae(y_test, y_pred)\n",
    "        rmse = calcular_rmse(y_test, y_pred)\n",
    "        wmape = calcular_wmape(y_test, y_pred)\n",
    "\n",
    "        metricas.append({\n",
    "            'cadena': cadena_name,\n",
    "            'regresion': reg_nombre,\n",
    "            'MAE': mae,\n",
    "            'RMSE': rmse,\n",
    "            'WMAPE': wmape,\n",
    "        })\n",
    "    \n",
    "metricas = pd.DataFrame(metricas)\n",
    "display(metricas)\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c42e2e6d",
   "metadata": {},
   "source": [
    "REGRESION - VALIDACION CRUZADA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a609434a",
   "metadata": {},
   "outputs": [],
   "source": [
    "kf = KFold(n_splits=5, shuffle=True, random_state=42)\n",
    "regresion_scores = pd.DataFrame()\n",
    "\n",
    "# Utiliza el iterador para volver a obtener (cadena, X, y).\n",
    "for cadena_name, X, y in iter_regresion_Xy():\n",
    "    puntajes = []\n",
    "    \n",
    "\t# Se realizará una validación cruzada de los modelos de regresión que se seleccionaron.\n",
    "    for reg_nombre, reg in all_regresion.items():\n",
    "        modelo = Pipeline([\n",
    "            ('scaler', StandardScaler()),\n",
    "            ('regresion', reg),\n",
    "        ])\n",
    "        \n",
    "        scores = cross_val_score(modelo, X, y, cv=kf, scoring='neg_mean_absolute_error')\n",
    "        \n",
    "        puntajes.append({\n",
    "            'cadena': cadena_name,\n",
    "            'regresion': reg_nombre,\n",
    "            'MAE score': -np.mean(scores)\n",
    "        })\n",
    "    \n",
    "\t# Se utiliza la métrica MAE para evaluar el mejor modelo.\n",
    "\t# El mejor puntaje es aquel cuya MAE sea menor.\n",
    "    puntajes = pd.DataFrame(puntajes)\n",
    "    puntajes['mejor'] = puntajes['MAE score'] == puntajes['MAE score'].min()\n",
    "    regresion_scores = pd.concat([regresion_scores, puntajes])\n",
    "\n",
    "display(regresion_scores)        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35eb68c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Graficar los mejores modelos de regresión para cada cadena.\n",
    "mejores_modelos = regresion_scores[regresion_scores.mejor == True][['cadena', 'regresion']]\n",
    "\n",
    "for cadena, regresion in mejores_modelos.values:\n",
    "    # Se carga el modelo previamente guardado en disco\n",
    "    modelo = cargar_modelo('regresion/{} - {}.joblib'.format(cadena, regresion))\n",
    "    \n",
    "    if modelo:\n",
    "        df = main_df[main_df.cadena == cadena]\n",
    "        y_pred = modelo.predict(df[['supermercado_id', 'cadena_id', 'producto_id']])\n",
    "\n",
    "        fig, ax = plt.subplots(1, 1, figsize=(10, 5))\n",
    "        ax.set_title('Estimaciones de costos para cadena de supermercados: %s' % cadena, fontsize=10)\n",
    "        ax.tick_params(axis='x', labelsize=6)\n",
    "        ax.tick_params(axis='y', labelsize=6)\n",
    "        ax.grid(True, color='#dedede')\n",
    "        \n",
    "        for x,y,label in [(df.fecha, df.costo, 'real'), (df.fecha, y_pred, 'regresión')]:\n",
    "            df = pd.DataFrame({'fecha':x, 'costo':y}).groupby(['fecha'])['costo'].mean().reset_index()\n",
    "            ax.plot(df.fecha, df.costo, label=label)\n",
    "\n",
    "    plt.legend()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b634bdc1",
   "metadata": {},
   "source": [
    "CLASIFICACION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a38e95aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Similar a la regresión, se crea un iterador que genera una tupla (cadena, X, y).\n",
    "def iter_clasificacion_Xy():\n",
    "    for cadena_id, cadena_name in unique_cadenas:\n",
    "        df = main_df[main_df.cadena_id == cadena_id][['supermercado_id', 'cadena_id', 'producto_id', 'costo', 'fecha']]\n",
    "        df = df.sort_values('fecha')\n",
    "\n",
    "        umbral = df['costo'].median()\n",
    "\n",
    "        df['target'] = (umbral < df['costo']).astype(int)\n",
    "        X = df[['supermercado_id', 'cadena_id', 'producto_id']]\n",
    "        y = df['target']\n",
    "\n",
    "        yield cadena_name, X, y\n",
    "\n",
    "# Se enlistan los modelos de clasificación que se utilizarán en el análisis.\n",
    "all_clasificacion = {\n",
    "    'Baseline': DummyClassifier(strategy=\"stratified\", random_state=42),\n",
    "    'LogisticRegression': LogisticRegression(max_iter=1000),\n",
    "    'RandomForest': RandomForestClassifier(random_state=42),\n",
    "    'HistGradientBoosting': HistGradientBoostingClassifier(random_state=42)\n",
    "}\n",
    "\n",
    "metricas = []\n",
    "\n",
    "for cadena_name, X, y in iter_clasificacion_Xy():\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, stratify=y, test_size=0.2, random_state=42)\n",
    "    \n",
    "    for cls_nombre, cls in all_clasificacion.items():\n",
    "        modelo = Pipeline([\n",
    "            ('scaler', StandardScaler()),\n",
    "            ('clasificador', cls),\n",
    "        ])\n",
    "        \n",
    "        modelo.fit(X_train, y_train)\n",
    "        y_pred = modelo.predict(X_test)\n",
    "        \n",
    "        # Se guarda el modelo en disco.\n",
    "        guardar_modelo(modelo, 'clasificacion/{} - {}.joblib'.format(cadena_name, cls_nombre))\n",
    "        \n",
    "        # Algunos modelos generan probabilidades, por lo que hay que verificar cuáles lo hacen.\n",
    "        if hasattr(modelo.named_steps[\"clasificador\"], \"predict_proba\"):\n",
    "            y_proba = modelo.predict_proba(X_test)[:, 1]\n",
    "        elif hasattr(modelo.named_steps[\"clasificador\"], \"decision_function\"):\n",
    "            y_proba = modelo.decision_function(X_test)\n",
    "        else:\n",
    "            y_proba = None\n",
    "\n",
    "        f1 = f1_score(y_test, y_pred, average='macro')\n",
    "        roc_auc = None if y_proba is None else roc_auc_score(y_test, y_proba)\n",
    "        pr_auc = None if y_proba is None else average_precision_score(y_test, y_proba)\n",
    "        \n",
    "        metricas.append({\n",
    "            'cadena': cadena_name,\n",
    "            'clasificador': cls_nombre,\n",
    "            'F1': f1,\n",
    "            'ROC-AUC': roc_auc,\n",
    "            'PR-AUC': pr_auc,\n",
    "        })\n",
    "\n",
    "metricas = pd.DataFrame(metricas)\n",
    "display(metricas)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c2430629",
   "metadata": {},
   "source": [
    "CLASIFICACION - VALIDACION CRUZADA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fed943db",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Validación cruzada para los modelos de clasificación.\n",
    "\n",
    "cv = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
    "clasificacion_scores = pd.DataFrame()\n",
    "\n",
    "# Los puntajes estarán basados en las métricas F1 obligatorio, ROC-AUC y PR-AUC\n",
    "scoring = {\n",
    "    'f1_macro': 'f1_macro',\n",
    "    'roc_auc': 'roc_auc',\n",
    "    'pr_auc': 'average_precision'  # PR-AUC\n",
    "}\n",
    "\n",
    "for cadena_name, X, y in iter_clasificacion_Xy():\n",
    "    puntajes = []\n",
    "    \n",
    "    for cls_nombre, cls in all_clasificacion.items():\n",
    "        scores = cross_validate(cls, X, y, cv=cv, scoring=scoring, return_train_score=False)\n",
    "        \n",
    "        puntajes.append({\n",
    "            'cadena': cadena_name,\n",
    "            'clasificador': cls_nombre,\n",
    "            'F1 score': np.mean(scores['test_f1_macro']),\n",
    "            'ROC-AUC score': np.mean(scores['test_roc_auc']),\n",
    "            'PR-AUC score': np.mean(scores['test_pr_auc'])\n",
    "        })\n",
    "    \n",
    "\t# Se utiliza F1 como métrica para determinar el mejor modelo. Esto debido a que el objetivo de la clasificación\n",
    "    # es determinar si el costo subirá o no de valor al siguiente mes. Para dicho análisis, F1 es la mejor opción.\n",
    "    # Mientras más alto el valor F1, mejor.\n",
    "    puntajes = pd.DataFrame(puntajes)\n",
    "    puntajes['mejor'] = puntajes['F1 score'] == puntajes['F1 score'].max()\n",
    "    clasificacion_scores = pd.concat([clasificacion_scores, puntajes])\n",
    "\n",
    "display(clasificacion_scores)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "modelos_predictivos (3.11.9)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
